
# üìù Publications

<div class='paper-box'><div class='paper-box-image'><div><div class="badge"></div><a href="image/H-SRDC.png"><img src='image/H-SRDC.png' alt="sym" width="100%"></a></div></div>
<div class='paper-box-text' markdown="1">

<b>Towards Uncovering the Intrinsic Data Structures for Unsupervised Domain Adaptation using Structurally Regularized Deep Clustering</b><br>
<i>IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI), 2022</i><br>
<b>Hui Tang</b>, Xiatian Zhu, Ke Chen, Kui Jia, and CL Philip Chen<br>
[<a href="https://arxiv.org/pdf/2012.04280">PDF</a>] [<a href="https://github.com/huitangtang/H-SRDC">Code</a>] [<a href="https://huitangtang.github.io/H-SRDC/">Page</a>]<br>
<div style="text-align: justify">
We are motivated by a Unsupervised domain adaptation (UDA) assumption of structural similarity across domains, 
and propose to directly uncover the intrinsic target discrimination via constrained clustering, 
where we constrain the clustering solutions using structural source regularization that hinges on the very same assumption. 
Technically, we propose a hybrid model of Structurally Regularized Deep Clustering, 
which integrates the regularized discriminative clustering of target data with a generative one, 
and we thus term our method as H-SRDC.
</div>
</div>

</div>



<div class='paper-box'><div class='paper-box-image'><div><div class="badge"></div><a href="image/DisClusterDA.png"><img src='image/DisClusterDA.png' alt="sym" width="100%"></a></div></div>
<div class='paper-box-text' markdown="1">

<b>Unsupervised domain adaptation via distilled discriminative clustering</b><br>
<i>Pattern Recognition, 2022</i><br>
<b>Hui Tang</b>, Yaowei Wang, and Kui Jia<br>
[<a href="https://arxiv.org/pdf/2302.11984">PDF</a>] [<a href="https://github.com/huitangtang/DisClusterDA">Code</a>] [<a href="https://kyanchen.github.io/DisClusterDA/">Page</a>]<br>
<div style="text-align: justify">
Motivated by the fundamental assumption for domain adaptability, we re-cast the domain adaptation problem as discriminative clustering of target data, 
given strong privileged information provided by the closely related, labeled source data. 
Technically, we use clustering objectives based on a robust variant of entropy minimization that adaptively filters target data, 
a soft Fisher-like criterion, and additionally the cluster ordering via centroid classification. 
To distill discriminative source information for target clustering, we propose to jointly train the network using parallel, supervised learning objectives over labeled source data. 
</div>
</div>

</div>


<div class='paper-box'><div class='paper-box-image'><div><div class="badge"></div><a href="image/ODSurvey.png"><img src='image/ODSurvey.png' alt="sym" width="100%"></a></div></div>
<div class='paper-box-text' markdown="1">

<b>Object Detection in 20 Years: A Survey</b><br>
<i>Proceedings of the IEEE (P IEEE), 2023</i><br>
Zhengxia Zou, <b>Keyan Chen</b>, Zhenwei Shi, Yuhong Guo and Jieping Ye<br>
[<a href="http://levir.buaa.edu.cn/publications/od_survey.pdf">PDF</a>] [<a href="https://github.com/KyanChen/ODSurvey">Code</a>] [<a href="https://kyanchen.github.io/ODSurvey/">Page</a>]<br>
<div style="text-align: justify">
This paper extensively reviews the fast-moving research field in the light of technical evolution, spanning over a quarter-century's time (from the 1990s to 2022). A number of topics have been covered, including the milestone detectors in history, detection datasets, metrics, fundamental building blocks of the detection system, speed-up techniques, and the recent state-of-the-art detection methods.
</div>

</div>
</div>


<div class='paper-box'><div class='paper-box-image'><div><div class="badge"></div><a href="image/RASNet.png"><img src='image/RASNet.png' alt="sym" width="100%"></a></div></div>
<div class='paper-box-text' markdown="1">

<b>Resolution-agnostic Remote Sensing Scene Classification with Implicit Neural Representations</b><br>
<i>IEEE Geoscience and Remote Sensing Letters (GRSL), 2022</i><br>
<b>Keyan Chen</b>, Wenyuan Li, Jianqi Chen, Zhengxia Zou and Zhenwei Shi<br>
[<a href="http://levir.buaa.edu.cn/publications/RASNet.pdf">PDF</a>] [<a href="https://github.com/KyanChen/RASNet">Code</a>] [<a href="https://kyanchen.github.io/RASNet/">Page</a>]<br>
<div style="text-align: justify">
We propose a novel scene classification method with scale and resolution adaptation ability. Unlike previous CNNbased methods that make predictions based on rasterized image inputs, the proposed method converts the images as continuous functions with INRs optimization and then performs classification within the function space.
</div>

</div>
</div>


<div class='paper-box'><div class='paper-box-image'><div><div class="badge"></div><a href="image/GeCo.png"><img src='image/GeCo.png' alt="sym" width="100%"></a></div></div>
<div class='paper-box-text' markdown="1">

<b>Geographical Supervision Correction for Remote Sensing Representation Learning</b><br>
<i>IEEE Transactions on Geoscience and Remote Sensing (TGRS), 2022</i><br>
Wenyuan Li, <b>Keyan Chen</b>, and Zhenwei Shi<br>
[<a href="http://levir.buaa.edu.cn/publications/FINAL_VERSION.pdf">PDF</a>]<br>
<div style="text-align: justify">
We propose a Geographical supervision Correction method (GeCo) for remote sensing representation learning. Deviated geographical supervision generated by GLC products can be corrected adaptively using the correction matrix during network pre-training and joint optimization process is designed to simultaneously update the correction matrix and network parameters.
</div>

</div>
</div>



<div class='paper-box'><div class='paper-box-image'><div><div class="badge"></div><a href="image/DRENet.png"><img src='image/DRENet.png' alt="sym" width="100%"></a></div></div>
<div class='paper-box-text' markdown="1">

<b>A Degraded Reconstruction Enhancement-based Method for Tiny Ship Detection in Remote Sensing Images with A New Large-scale Dataset</b><br>
<i>IEEE Transactions on Geoscience and Remote Sensing (TGRS), 2022</i><br>
Jianqi Chen, <b>Keyan Chen</b>, Hao Chen, Zhengxia Zou and Zhenwei Shi<br>
[<a href="http://levir.buaa.edu.cn/publications/DRENet.pdf">PDF</a>] [<a href="https://github.com/WindVChen/DRENet">Code</a>] [<a href="https://github.com/windvchen/levir-ship">Dataset</a>]<br>
<div style="text-align: justify">
We propose a tiny ship detection method namely, Degraded Reconstruction Enhancement Network (DRENet), for medium-resolution remote sensing images, and introduce Levir-Ship, which contains 3876 GF-1/GF-6 multi-spectral images and over 3K tiny ship instances.
</div>

</div>
</div>


<div class='paper-box'><div class='paper-box-image'><div><div class="badge"></div><a href="image/P2Net.png"><img src='image/P2Net.png' alt="sym" width="100%"></a></div></div>
<div class='paper-box-text' markdown="1">

<b>Contrastive Learning for Fine-grained Ship Classification in Remote Sensing Images</b><br>
<i>IEEE Transactions on Geoscience and Remote Sensing (TGRS), 2022</i><br>
Jianqi Chen, <b>Keyan Chen</b>, Hao Chen, Wenyuan Li, Zhengxia Zou, and Zhenwei Shi<br>
[<a href="http://levir.buaa.edu.cn/publications/CLFSC.pdf">PDF</a>] [<a href="https://github.com/WindVChen/Push-and-Pull-Network">Code</a>]<br>
<div style="text-align: justify">
We propose an asynchronous contrastive learning-based method for effective fine-grained ship classification, which refers to as "Push-and-Pull Network (P2Net)", includes a "push-out stage" and a "pull-in stage", where the first stage forces all the instances to be de-correlated and then the second one groups them into each subclass.
</div>

</div>
</div>


<div class='paper-box'><div class='paper-box-image'><div><div class="badge"></div><a href="image/GeoKR.png"><img src='image/GeoKR.png' alt="sym" width="100%"></a></div></div>
<div class='paper-box-text' markdown="1">

<b>Geographical Knowledge-Driven Representation Learning for Remote Sensing Images</b><br>
<i>IEEE Transactions on Geoscience and Remote Sensing (TGRS), 2021</i><br>
Wenyuan Li, <b>Keyan Chen</b>, Hao Chen and Zhenwei Shi<br>
[<a href="http://levir.buaa.edu.cn/publications/Geographical_Knowledge-Driven.pdf">PDF</a>] [<a href="https://github.com/flyakon/Geographical-Knowledge-driven-Representaion-Learning">Code</a>]<br>
<div style="text-align: justify">
 We propose a Geographical Knowledge-driven Representation learning method for remote sensing images (GeoKR), improving network performance and reduce the demand for annotated data. The global land cover products and geographical location associated with each remote sensing image are regarded as geographical knowledge to provide supervision for representation learning and network pre-training.
</div>

</div>
</div>


<div class='paper-box'><div class='paper-box-image'><div><div class="badge"></div><a href="image/STT.png"><img src='image/STT.png' alt="sym" width="100%"></a></div></div>
<div class='paper-box-text' markdown="1">

<b>Building Extraction from Remote Sensing Images with Sparse Token Transformers</b><br>
<i>Remote Sensing, 2021</i><br>
<b>Keyan Chen</b>, Zhengxia Zou and Zhenwei Shi<br>
[<a href="https://www.mdpi.com/2072-4292/13/21/4441">PDF</a>] [<a href="https://github.com/KyanChen/STT">Code</a>] [<a href="https://kyanchen.github.io/STT/">Page</a>] [<a href="https://huggingface.co/spaces/KyanChen/BuildingExtraction">Demo</a>]<br>
<div style="text-align: justify">
We propose STT to explore the potential of using transformers for efficient building extraction. STT conducts an efficient dual-pathway transformer that learns the global semantic information in both their spatial and channel dimensions and achieves state-of-the-art accuracy on two building extraction benchmarks.
</div>

</div>
</div>
